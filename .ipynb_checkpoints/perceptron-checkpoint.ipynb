{
 "metadata": {
  "name": "",
  "signature": "sha256:a1ecd564dd1a6b743fe05098797a4314404a5efd0b12e2d425481b3ed62869e1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Perceptron Classifier"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Overview"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook shows how to implement a binary classifier using a perceptron with a sigmoidal unit. The data used for this project are hand written digits. The note book only shows the result, through use of a confusion matrix, of one possible combination of digits; however, the notebook could easily be modified to output the confusion matrix of all possible digit combinations."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Zip Code Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p>The zip code data for this notebook can be found at the website of \"<a href=http://statweb.stanford.edu/~tibs/ElemStatLearn/>The Elements of \n",
      "Statistical Learning</a>\" (ESL). The data consists of 7291 training observation and 2007 test observation. Each observation is 16 x 16 grayscale image of a handwritten zip code digit, ranging from zero to nine.</p>\n",
      "<table width=\"100%\" style=\"border:none;\">\n",
      "    <tr bgcolor=\"AliceBlue\" style=\"border:none;\">\n",
      "        <td style=\"border:none;\"></td>\n",
      "        <td style=\"border:none;\">Zero</td>\n",
      "        <td style=\"border:none;\">One</td>\n",
      "        <td style=\"border:none;\">Two</td>\n",
      "        <td style=\"border:none;\">Three</td>\n",
      "        <td style=\"border:none;\">Four</td>\n",
      "        <td style=\"border:none;\">Five</td>\n",
      "        <td style=\"border:none;\">Six</td>\n",
      "        <td style=\"border:none;\">Seven</td>\n",
      "        <td style=\"border:none;\">Eight</td>\n",
      "        <td style=\"border:none;\">Nine</td>\n",
      "        <td style=\"border:none;\">Total Observations</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\">\n",
      "        <td bgcolor=\"AliceBlue\" style=\"border:none;\">Training Data</td>\n",
      "        <td style=\"border:none;\">1194</td>\n",
      "        <td style=\"border:none;\">1005</td>\n",
      "        <td style=\"border:none;\">731</td>\n",
      "        <td style=\"border:none;\">658</td>\n",
      "        <td style=\"border:none;\">652</td>\n",
      "        <td style=\"border:none;\">556</td>\n",
      "        <td style=\"border:none;\">664</td>\n",
      "        <td style=\"border:none;\">645</td>\n",
      "        <td style=\"border:none;\">542</td>\n",
      "        <td style=\"border:none;\">644</td>\n",
      "        <td style=\"border:none;\">7291</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\">\n",
      "        <td bgcolor=\"AliceBlue\" style=\"border:none;\">Test Data</td>\n",
      "        <td style=\"border:none;\">359</td>\n",
      "        <td style=\"border:none;\">264</td>\n",
      "        <td style=\"border:none;\">198</td>\n",
      "        <td style=\"border:none;\">166</td>\n",
      "        <td style=\"border:none;\">200</td>\n",
      "        <td style=\"border:none;\">160</td>\n",
      "        <td style=\"border:none;\">170</td>\n",
      "        <td style=\"border:none;\">147</td>\n",
      "        <td style=\"border:none;\">166</td>\n",
      "        <td style=\"border:none;\">177</td>\n",
      "        <td style=\"border:none;\">2007</td>\n",
      "    </tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Building the Classifier"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<p>When building this classifier Raul Rojas', <a href=\"http://www.inf.fu-berlin.de/inst/ag-ki/rojas_home/pmwiki/pmwiki.phpXn=Books.NeuralNetworksBook\">Neural Networks - A Systematic Introduction</a> was used as a reference. The following steps were taken to build the classifier:</p>\n",
      "<ol>\n",
      "    <li>An initial vector of weights, $\\vec{\\beta}$, is created</li>\n",
      "    <li>The sigmoid function is caculated for each observation, $S\\left ( \\mathbf{X_{i}}\\right )=\\frac{1}{1+e^{-\\vec{\\beta}^{T}\\mathbf{X_{i}}}}=\\begin{cases}& \\text{ if }>  0.50\\text{, } \\hat{y}= 1\\\\  & \\text{ else, } \\hat{y}= 0\\end{cases}$</li>\n",
      "    <li>The sum of errors is collected, $E=\\frac{1}{2}\\sum \\left ( \\hat{y}-y_{i} \\right )^{2}$</li>\n",
      "    <li>The gradient of the error is caculated, $\\triangledown E$</li>\n",
      "    <li>and gradient descent is used to update the weights, $\\vec{\\beta _{new}}=\\vec{\\beta _{old}} - \\gamma \\triangledown E$</li>\n",
      "    <li>Steps 2-5 are repeated till the difference in the current and previous errors is insignificant</li>\n",
      "</ol>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Python Code"
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Imported Libraries"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import gzip\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Defined Functions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<table width=\"100%\" style=\"border:none;\">\n",
      "    <tr style=\"border:none;\" bgcolor=\"#F0F8FF\">\n",
      "        <td style=\"border:none;\">name:</td>\n",
      "        <td style=\"border:none;\">define_binary_data</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\">description:</td>\n",
      "        <td style=\"border:none;\">function removes all data related to two class labels from an N x M matrix and returns N_new x M matrix</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\" bgcolor=\"#F0F8FF\">\n",
      "        <td style=\"border:none;\">dependencies:</td>\n",
      "        <td style=\"border:none;\">none</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\">inputs:</td>\n",
      "        <td style=\"border:none;\">data - is an N x M matrix containing labels</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\"></td>\n",
      "        <td style=\"border:none;\">label_idx - is the column containing the labels of the data</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\"></td>\n",
      "        <td style=\"border:none;\">label_a - is labeled data from the N x M matrix that will be kept and re-labeled as 0</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\"></td>\n",
      "        <td style=\"border:none;\">label_b - is labeled data from the N x M matrix that will be kept and re-labeled as 1</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\" bgcolor=\"#F0F8FF\">\n",
      "        <td style=\"border:none;\">outputs:</td>\n",
      "        <td style=\"border:none;\">returns N_new x M matrix composed of the two labels extracted from the orginal N x M matrix</td>\n",
      "    </tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def define_binary_data(data, label_idx, label_a, label_b):\n",
      "    \n",
      "    # extract labels 1 and 2 from data\n",
      "    data_label_a = data[data[:,label_idx] == label_a]\n",
      "    data_label_b = data[data[:,label_idx] == label_b]\n",
      "    \n",
      "    # re-label data: label_1 = 0 and label_2 = 1\n",
      "    data_label_a[:,label_idx] = 0\n",
      "    data_label_b[:,label_idx] = 1\n",
      "    \n",
      "    # verticaly stack matrices and randomly shuffle rows\n",
      "    binary_data = np.vstack((data_label_a, data_label_b))\n",
      "    np.random.shuffle(binary_data)\n",
      "    \n",
      "    return binary_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<table width=\"100%\" style=\"border:none;\">\n",
      "    <tr style=\"border:none;\" bgcolor=\"#F0F8FF\">\n",
      "        <td style=\"border:none;\">name:</td>\n",
      "        <td style=\"border:none;\">ad_bias</td>\n",
      "    </tr>\n",
      "        <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\">description:</td>\n",
      "        <td style=\"border:none;\">function takes a matrix of binay labeled data and returns that matrix with an added row of ones at index zero</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\" bgcolor=\"#F0F8FF\">\n",
      "        <td style=\"border:none;\">dependencies:</td>\n",
      "        <td style=\"border:none;\">none</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\">inputs:</td>\n",
      "        <td style=\"border:none;\">data - is an N x M matrix containing binary labeled data</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\" bgcolor=\"#F0F8FF\">\n",
      "        <td style=\"border:none;\">outputs:</td>\n",
      "        <td style=\"border:none;\">returns N+1 x M composed of the orginal input matrix and an additional row for bias</td>\n",
      "    </tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def add_bias(data):\n",
      "    \n",
      "    # create bias vector\n",
      "    bias = np.ones((1,data.shape[1]))\n",
      "    \n",
      "    # return verticaly stacked bias on data\n",
      "    return np.vstack((bias, data))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<table width=\"100%\" style=\"border:none;\">\n",
      "    <tr style=\"border:none;\" bgcolor=\"#F0F8FF\">\n",
      "        <td style=\"border:none;\">name:</td>\n",
      "        <td style=\"border:none;\">initial_beta</td>\n",
      "    </tr>\n",
      "        <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\">description:</td>\n",
      "        <td style=\"border:none;\">function initializes a vector of weights by taking the mean difference of the two labeled data classes</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\" bgcolor=\"#F0F8FF\">\n",
      "        <td style=\"border:none;\">dependencies:</td>\n",
      "        <td style=\"border:none;\">none</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\">inputs</td>\n",
      "        <td style=\"border:none;\">data - is a N x M matrix containg only binary labeled data with a bias added</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\" bgcolor=\"#F0F8FF\">\n",
      "        <td style=\"border:none;\">outputs</td>\n",
      "        <td style=\"border:none;\">returns an initial vector of weights (gamma)</td>\n",
      "    </tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def initial_beta(data, label_idx):\n",
      "    \n",
      "    # extract labels 0 and 1 from data\n",
      "    data_label_0 = data[data[:,label_idx] == 0][:,1:]\n",
      "    data_label_1 = data[data[:,label_idx] == 1][:,1:]\n",
      "    \n",
      "    # caculate means of the column vectors\n",
      "    mean_0 = np.mean(data_label_0, axis=0)[:,np.newaxis]\n",
      "    mean_1 = np.mean(data_label_1, axis=0)[:,np.newaxis]\n",
      "    \n",
      "    # return the difference of the means for labels 0 and 1\n",
      "    return mean_0 - mean_1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<table width=\"100%\" style=\"border:none;\">\n",
      "    <tr style=\"border:none;\" bgcolor=\"#F0F8FF\">\n",
      "        <td style=\"border:none;\">name:</td>\n",
      "        <td style=\"border:none;\">prepare_data</td>\n",
      "    </tr>\n",
      "        <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\">description:</td>\n",
      "        <td style=\"border:none;\">function takes a matrix of raw data which it extracts all the data involving two specified classes and builds another matrix of binary labeled data; It then adds a bias to the new matrix and creates an initial vector of weights, based on this new matrix; in addition to seperating the data from its labels</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\" bgcolor=\"#F0F8FF\">\n",
      "        <td style=\"border:none;\">dependencies:</td>\n",
      "        <td style=\"border:none;\">define_binary_data, add_bias, initial_beta</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\">inputs</td>\n",
      "        <td style=\"border:none;\">data - is an N x M matrix containing labels</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\"></td>\n",
      "        <td style=\"border:none;\">label_idx - is the column containing the labels of the data</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\"></td>\n",
      "        <td style=\"border:none;\">label_a - is labeled data from the N x M matrix that will be kept and re-labeled as 0</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\"></td>\n",
      "        <td style=\"border:none;\">label_b - is labeled data from the N x M matrix that will be kept and re-labeled as 1</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\" bgcolor=\"#F0F8FF\">\n",
      "        <td style=\"border:none;\">outputs</td>\n",
      "        <td style=\"border:none;\">returns an initial vector of weights (beta), a matrix of observations (X), and a vector of labels (y)</td>\n",
      "    </tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def prepare_data(train_data, label_idx, label_a, label_b):\n",
      "    \n",
      "    # generate a new matrix, from the raw data, based on the specified labels and add a bias row\n",
      "    new_data = add_bias(define_binary_data(train_data, label_idx, label_a, label_b))\n",
      "    \n",
      "    # return beta, X, and y\n",
      "    return new_data[:,1:], new_data[:,0].astype(int)[:,np.newaxis], initial_beta(new_data, label_idx)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<table width=\"100%\" style=\"border:none;\">\n",
      "    <tr style=\"border:none;\" bgcolor=\"#F0F8FF\">\n",
      "        <td style=\"border:none;\">name:</td>\n",
      "        <td style=\"border:none;\">train</td>\n",
      "    </tr>\n",
      "        <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\">description:</td>\n",
      "        <td style=\"border:none;\">function uses gradient descent to update beta (vector of coeficients or weights) to minimize the error of the function output</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\" bgcolor=\"#F0F8FF\">\n",
      "        <td style=\"border:none;\">dependencies:</td>\n",
      "        <td style=\"border:none;\">none</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\">inputs</td>\n",
      "        <td style=\"border:none;\">X - a matrix of observations</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\"></td>\n",
      "        <td style=\"border:none;\">y - a vector of labels</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\"></td>\n",
      "        <td style=\"border:none;\">beta - an initial vector of weights</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\" bgcolor=\"#F0F8FF\">\n",
      "        <td style=\"border:none;\">outputs</td>\n",
      "        <td style=\"border:none;\">returns an update version of beta that minimizes the error of the function </td>\n",
      "    </tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train(X, y, beta, step_size=0.1, significant_figures=1E-4):\n",
      "    \n",
      "    # initialize some variables\n",
      "    error_flag = True\n",
      "    previous_error = 0\n",
      "    \n",
      "    # while the difference in the current error and previous error is significant \n",
      "    while error_flag:\n",
      "\n",
      "        # initialize error and error gradient to zeros\n",
      "        error = 0\n",
      "        error_gradient_sum = np.zeros(beta.shape)\n",
      "\n",
      "        # iterate through each observation\n",
      "        for observation_idx in range(X.shape[0]):\n",
      "\n",
      "            # get current observation\n",
      "            x = X[observation_idx][:,np.newaxis]\n",
      "\n",
      "            # caculate y_hat using sigmoid function\n",
      "            y_hat = 1 / (1 + np.exp(np.dot(-beta.T, x)))\n",
      "            \n",
      "            # convert y_hat to binary output\n",
      "            y_hat = np.where(y_hat >= 0.5, 0, 1) # should be: y_hats <= 0.5, 0, 1\n",
      "\n",
      "            # caculate the error and add to sum of errors\n",
      "            difference = y_hat - y[observation_idx]\n",
      "            error += 0.5 * (difference)**2\n",
      "\n",
      "            # caculate gradient of error and add it to the sum of gradient errors\n",
      "            error_gradient = (difference * y_hat * (1 - y_hat)) * x\n",
      "            error_gradient_sum = np.sum(np.hstack(( error_gradient_sum, error_gradient)), axis=1)[:,np.newaxis]\n",
      "\n",
      "        # check if the difference in the current error and previous error is significant\n",
      "        if abs(previous_error - error) < significant_figures:\n",
      "            error_flag = False\n",
      "\n",
      "        # else update weights (beta)\n",
      "        else:\n",
      "            previous_error = error\n",
      "            beta -= step_size * error_gradient_sum\n",
      "            \n",
      "    # return vector of weights\n",
      "    return beta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<table width=\"100%\" style=\"border:none;\">\n",
      "    <tr style=\"border:none;\" bgcolor=\"#F0F8FF\">\n",
      "        <td style=\"border:none;\">name:</td>\n",
      "        <td style=\"border:none;\">predict</td>\n",
      "    </tr>\n",
      "        <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\">description:</td>\n",
      "        <td style=\"border:none;\">function predicts labels using a binary perceptron classifier</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\" bgcolor=\"#F0F8FF\">\n",
      "        <td style=\"border:none;\">dependencies:</td>\n",
      "        <td style=\"border:none;\">none</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\">inputs</td>\n",
      "        <td style=\"border:none;\">X - is a N+1 x M matrix of observations with bias added to the first row</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\"></td>\n",
      "        <td style=\"border:none;\">beta - a vector of weights/coeficients</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\" bgcolor=\"#F0F8FF\">\n",
      "        <td style=\"border:none;\">outputs</td>\n",
      "        <td style=\"border:none;\">return a vector of predicted labels</td>\n",
      "    </tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict(X, beta):\n",
      "    \n",
      "    # create an empty array to store y_hats\n",
      "    y_hats = np.empty((X.shape[0], 1))\n",
      "    \n",
      "    # iterate through each observation\n",
      "    for observation_idx in range(X.shape[0]):\n",
      "\n",
      "        # get current observation\n",
      "        x = X[observation_idx][:,np.newaxis]\n",
      "\n",
      "        # caculate y_hat using sigmoid function and add y_hat to array of y_hats\n",
      "        y_hats[observation_idx] = 1 / (1 + np.exp(np.dot(-beta.T, x)))\n",
      "        \n",
      "    # return y_hats converted to binary\n",
      "    return np.where(y_hats >= 0.5, 0, 1) # should be: y_hats <= 0.5, 0, 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<table width=\"100%\" style=\"border:none;\">\n",
      "    <tr style=\"border:none;\" bgcolor=\"#F0F8FF\">\n",
      "        <td style=\"border:none;\">name:</td>\n",
      "        <td style=\"border:none;\">confusion_scores</td>\n",
      "    </tr>\n",
      "        <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\">description:</td>\n",
      "        <td style=\"border:none;\">function creates a confusion matrix with the percentage of correctly/incorectly classified labels</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\" bgcolor=\"#F0F8FF\">\n",
      "        <td style=\"border:none;\">dependencies:</td>\n",
      "        <td style=\"border:none;\">none</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\">inputs</td>\n",
      "        <td style=\"border:none;\">y_hat - predicted labels</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\">\n",
      "        <td style=\"border:none;\"></td>\n",
      "        <td style=\"border:none;\">y - actual labels</td>\n",
      "    </tr>\n",
      "    <tr style=\"border:none;\" bgcolor=\"#F0F8FF\">\n",
      "        <td style=\"border:none;\">outputs</td>\n",
      "        <td style=\"border:none;\">returns confusion matrix</td>\n",
      "    </tr>\n",
      "</table>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def confusion_scores(y_hat, y):\n",
      "    \n",
      "    # initialize a 2 x 2 matrix of zeros\n",
      "    matrix = np.zeros((2,2))\n",
      "    \n",
      "    # increment cell coresponding to actual (row) and predicted (col)\n",
      "    for prediction_idx in range(y_hat.shape[0]):\n",
      "        row = y[prediction_idx]\n",
      "        col = y_hat[prediction_idx]\n",
      "        matrix[row,col] += 1\n",
      "        \n",
      "    # get quantity of actual zeros and ones\n",
      "    zeros = y[y[:] == 0].shape[0]\n",
      "    ones = y[y[:] == 1].shape[0]\n",
      "    \n",
      "    # return confision matrix scores\n",
      "    return np.divide(matrix, np.array((zeros,ones))[:,np.newaxis]).round(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Extract the training data from its file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with gzip.open('../Data/zip.train.gz') as f:\n",
      "    train_data = np.loadtxt(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define index of labels in the training data and the two labels, choose between digits 0 and 9, to be used with the perceptron"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "label_idx = 0\n",
      "label_a = 2\n",
      "label_b = 3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Prepare the training data to be used in finding the correct weights"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, y_train, beta_initial = prepare_data(train_data, label_idx, label_a, label_b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Update beta to minimize the error of the perceptron"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beta = train(X_train, y_train, beta_initial)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Extract the testing data from its file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with gzip.open('../Data/zip.test.gz') as f:\n",
      "    test_data = np.loadtxt(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Prepare the testing data to predict labels using a perceptron"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test, y_test, _ = prepare_data(test_data, label_idx, label_a, label_b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use new weight coeficients to classify test set and print confusion matrix scores"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print confusion_scores(predict(X_test, beta), y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.77  0.23]\n",
        " [ 0.01  0.99]]\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Thoughts "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, some kind of feature reduction would help increase the scores of the data, but I'd also like to look at the difference between using a batch update versus an inline update. The function train is currently using a batch update. In Addition, there is an issue with functions train and predict, as the logic for classifying based on a probability is opposite of what it should be. I added comments where this occurs and what the logic should be. "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}